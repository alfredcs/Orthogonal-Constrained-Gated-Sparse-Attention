2026-01-13 23:26:29 - INFO - __main__ - Wandb initialized: https://wandb.ai/alfredcs_team/orthgsa-qwen3-4b/runs/iqf2er0o
2026-01-13 23:26:30 - INFO - __main__ - Loading model: Qwen/Qwen3-4B-Instruct-2507
2026-01-13 23:26:30 - INFO - orthgsa.models.orthgsa_model - Loading base model: Qwen/Qwen3-4B-Instruct-2507
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 72.04it/s]
2026-01-13 23:26:31 - INFO - orthgsa.models.orthgsa_model - OrthGSA model initialized with 4 streams
2026-01-13 23:26:31 - INFO - __main__ - Model parameters: 4031.69M total, 4031.69M trainable
2026-01-13 23:26:31 - INFO - __main__ - Gradient checkpointing enabled
2026-01-13 23:26:34 - INFO - __main__ - Model wrapped with FSDP
2026-01-13 23:26:34 - INFO - orthgsa.utils.training_utils - Optimizer groups: 0 decay params, 760 no-decay params
2026-01-13 23:26:34 - INFO - orthgsa.utils.training_utils - Using fused AdamW optimizer
2026-01-13 23:26:34 - INFO - orthgsa.utils.training_utils - LR scheduler: cosine, warmup=3000, total=100000
2026-01-13 23:26:34 - INFO - orthgsa.data.slimpajama - Loading cerebras/SlimPajama-627B (streaming, packed, split=train)
2026-01-13 23:27:57 - INFO - orthgsa.data.slimpajama - Loading cerebras/SlimPajama-627B (streaming, packed, split=train)
2026-01-13 23:28:19 - INFO - __main__ - Starting training...
Training:   0%|                                                                                                                                                          | 0/100000 [00:00<?, ?it/s]
