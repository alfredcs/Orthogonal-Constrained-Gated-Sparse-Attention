2026-01-13 23:50:25 - INFO - __main__ - Wandb initialized: https://wandb.ai/alfredcs_team/orthgsa-qwen3-4b/runs/ei629hi8
2026-01-13 23:50:25 - INFO - __main__ - Loading model: Qwen/Qwen3-4B-Instruct-2507
2026-01-13 23:50:26 - INFO - orthgsa.models.orthgsa_model - Loading base model: Qwen/Qwen3-4B-Instruct-2507
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 70.19it/s]
2026-01-13 23:50:26 - INFO - orthgsa.models.orthgsa_model - OrthGSA model initialized with 4 streams
2026-01-13 23:50:26 - INFO - __main__ - Model parameters: 4031.69M total, 4031.69M trainable
2026-01-13 23:50:26 - INFO - __main__ - Gradient checkpointing enabled
2026-01-13 23:50:30 - INFO - __main__ - Model wrapped with FSDP
2026-01-13 23:50:30 - INFO - orthgsa.utils.training_utils - Optimizer groups: 0 decay params, 760 no-decay params
2026-01-13 23:50:30 - INFO - orthgsa.utils.training_utils - Using fused AdamW optimizer
2026-01-13 23:50:30 - INFO - orthgsa.utils.training_utils - LR scheduler: cosine, warmup=3000, total=100000
2026-01-13 23:50:30 - INFO - orthgsa.data.slimpajama - Loading cerebras/SlimPajama-627B (streaming, packed, split=train)
2026-01-13 23:51:19 - INFO - orthgsa.data.slimpajama - Loading cerebras/SlimPajama-627B (streaming, packed, split=train)
2026-01-13 23:51:41 - INFO - __main__ - Starting training...
Training:   0%|                                                                                                                                                          | 0/100000 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/home/alfred/codes/Orthogonal-Constrained-Gated-Sparse-Attention/scripts/train.py", line 457, in <module>
    main()
  File "/home/alfred/codes/Orthogonal-Constrained-Gated-Sparse-Attention/scripts/train.py", line 359, in main
    step_metrics = train_step(
                   ^^^^^^^^^^^
  File "/home/alfred/codes/Orthogonal-Constrained-Gated-Sparse-Attention/scripts/train.py", line 126, in train_step
    loss.backward()
  File "/home/alfred/codes/Orthogonal-Constrained-Gated-Sparse-Attention/.venv/lib/python3.11/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/alfred/codes/Orthogonal-Constrained-Gated-Sparse-Attention/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/alfred/codes/Orthogonal-Constrained-Gated-Sparse-Attention/.venv/lib/python3.11/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: setStorage: sizes [16, 10240], strides [10240, 1], storage offset 4031522288, and itemsize 2 requiring a storage size of 8063372256 are out of bounds for storage of size 0
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/alfred/codes/Orthogonal-Constrained-Gated-Sparse-Attention/scripts/train.py", line 457, in <module>
[rank0]:     main()
[rank0]:   File "/home/alfred/codes/Orthogonal-Constrained-Gated-Sparse-Attention/scripts/train.py", line 359, in main
[rank0]:     step_metrics = train_step(
[rank0]:                    ^^^^^^^^^^^
[rank0]:   File "/home/alfred/codes/Orthogonal-Constrained-Gated-Sparse-Attention/scripts/train.py", line 126, in train_step
[rank0]:     loss.backward()
[rank0]:   File "/home/alfred/codes/Orthogonal-Constrained-Gated-Sparse-Attention/.venv/lib/python3.11/site-packages/torch/_tensor.py", line 625, in backward
[rank0]:     torch.autograd.backward(
[rank0]:   File "/home/alfred/codes/Orthogonal-Constrained-Gated-Sparse-Attention/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py", line 354, in backward
[rank0]:     _engine_run_backward(
[rank0]:   File "/home/alfred/codes/Orthogonal-Constrained-Gated-Sparse-Attention/.venv/lib/python3.11/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
[rank0]:     return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]: RuntimeError: setStorage: sizes [16, 10240], strides [10240, 1], storage offset 4031522288, and itemsize 2 requiring a storage size of 8063372256 are out of bounds for storage of size 0
