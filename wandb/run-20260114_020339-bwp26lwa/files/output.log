2026-01-14 02:03:40 - INFO - __main__ - Wandb initialized: https://wandb.ai/alfredcs_team/orthgsa-qwen3-4b/runs/bwp26lwa
2026-01-14 02:03:41 - INFO - __main__ - Loading model: Qwen/Qwen3-4B-Instruct-2507
2026-01-14 02:03:41 - INFO - orthgsa.models.orthgsa_model - Loading base model: Qwen/Qwen3-4B-Instruct-2507
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 54.69it/s]
2026-01-14 02:03:41 - INFO - orthgsa.models.orthgsa_model - OrthGSA model initialized with 4 streams
2026-01-14 02:03:41 - INFO - __main__ - Model parameters: 4031.69M total, 4031.69M trainable
2026-01-14 02:03:41 - INFO - __main__ - Gradient checkpointing enabled
2026-01-14 02:03:41 - INFO - orthgsa.data.slimpajama - Loading from local path: /home/alfred/datasets/SlimPajama-627B (streaming, packed, split=train)
2026-01-14 02:06:08 - INFO - orthgsa.data.slimpajama - Loading from local path: /home/alfred/datasets/SlimPajama-627B (streaming, packed, split=train)
Before initializing optimizer states
MA 11.26 GB         Max_MA 13.14 GB         CA 13.16 GB         Max_CA 13 GB
CPU Virtual Memory:  used = 30.92 GB, percent = 4.1%
After initializing optimizer states
MA 11.26 GB         Max_MA 15.02 GB         CA 16.92 GB         Max_CA 17 GB
CPU Virtual Memory:  used = 31.07 GB, percent = 4.2%
After initializing ZeRO optimizer
MA 11.26 GB         Max_MA 11.26 GB         CA 16.92 GB         Max_CA 17 GB
CPU Virtual Memory:  used = 31.99 GB, percent = 4.3%
[2026-01-14 02:09:11,405] [WARNING] [lr_schedules.py:690:get_lr] Attempting to get learning rate from scheduler before it has started
2026-01-14 02:09:11 - INFO - __main__ - DeepSpeed engine initialized
2026-01-14 02:09:11 - INFO - __main__ - Starting training...
Training:   0%|                                                                                                                                            | 10/100000 [15:47<2644:37:39, 95.22s/it]2026-01-14 02:24:59 - INFO - orthgsa.utils.training_utils - Step 10 [train]: loss=380.8062, learning_rate=0.0000, gpu_memory_gb=22.5100
Training:   0%|                                                                                                                                            | 20/100000 [31:39<2641:25:35, 95.11s/it]2026-01-14 02:40:50 - INFO - orthgsa.utils.training_utils - Step 20 [train]: loss=382.0000, learning_rate=0.0000, gpu_memory_gb=22.5100
Training:   0%|                                                                                                                                            | 30/100000 [47:29<2639:22:54, 95.05s/it]2026-01-14 02:56:41 - INFO - orthgsa.utils.training_utils - Step 30 [train]: loss=382.0000, learning_rate=0.0000, gpu_memory_gb=22.5100
